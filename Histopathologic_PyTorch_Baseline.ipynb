{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.1"
    },
    "colab": {
      "name": "Histopathologic-PyTorch-Baseline",
      "provenance": [],
      "collapsed_sections": []
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9ejirCwJEp1n",
        "colab_type": "text"
      },
      "source": [
        "# Histopathologic Cancer Detection Competition"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FdZh-1JepXmP",
        "colab_type": "text"
      },
      "source": [
        "This notebook is a PyTorch baseline for iterative testing."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mGuesr1XEp1o",
        "colab_type": "code",
        "outputId": "c033bf5d-bcf0-493a-af89-835d51e6968d",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Comment out if in Colab\n",
        "# %reload_ext autoreload\n",
        "# %autoreload 2\n",
        "# %matplotlib inline\n",
        "\n",
        "# Colab drive mount\n",
        "# from google.colab import drive\n",
        "# drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_MaH5PnAEp1v",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "import os\n",
        "import pandas as pd\n",
        "import torch\n",
        "from pathlib import Path\n",
        "from torch.optim import Adam\n",
        "from torchvision.models.resnet import BasicBlock\n",
        "from torch.utils.data import DataLoader\n",
        "from torch.utils.data import Dataset\n",
        "from PIL import Image\n",
        "from matplotlib import pyplot as plt\n",
        "from torchvision.models.resnet import ResNet\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from torch import Tensor\n",
        "from torchvision import transforms\n",
        "from torch.autograd import Variable\n",
        "from pathlib import Path\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from tqdm import tqdm_notebook\n",
        "import random\n",
        "from typing import Optional, Tuple, List, Union\n",
        "import logging\n",
        "from functools import partial"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LJlY-460Ep17",
        "colab_type": "text"
      },
      "source": [
        "## Data Prep"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GUjKHqOvEp18",
        "colab_type": "text"
      },
      "source": [
        "Our data consists of a subset *histopathological images of lymph nodes stained with hematoxylin and eosin (H&E)* from the Patch Camelyon (PCAM) 2016 dataset:  https://github.com/basveeling/pcam\n",
        "- 220k training images and 57k evaluation 96x96 images, the only difference from PCAM being that duplicates are removed\n",
        "- Images from Camylon16 Challenge '16 https://camelyon16.grand-challenge.org/Data/ are digitized at 2 different centers at 40x\n",
        "    - PCAM uses 10x under sampling to increase FOV--resultant pixel resolution is 2.43 microns\n",
        "- Training set is ~0.595 positive where positive denotes at least 1 pixel of tumor tissue in the 32x32 center region of the image--**tumor tissue outside the 32x32 region does not influence the label**\n",
        "    - Thus we should crop images to the center region, but not too close as to lose features\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5BL_iLkFEp1x",
        "colab_type": "text"
      },
      "source": [
        "#### Downloading Data "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uwRryhBXFOd_",
        "colab_type": "text"
      },
      "source": [
        "Dataset is available at https://www.kaggle.com/c/histopathologic-cancer-detection/data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rtrLcc70Ep1y",
        "colab_type": "code",
        "outputId": "0d6a182e-bdae-4a8f-b3e1-86ccba3da7f0",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# Replace '/content/drive/My Drive/histopath' with your own respective working directory\n",
        "# %cd /content/drive/My Drive/histopath \n",
        "path = Path('/content/drive/My Drive/histopath')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/content/drive/My Drive/histopath\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tul3mqQ-s16K",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# unzipping WSI patch id's\n",
        "# !gunzip 'patch_ids.csv.gz'"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "SuHVGoMgw2r0",
        "colab_type": "code",
        "outputId": "daeccd07-1c42-46a8-b045-6b1c6c7fdb5a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "# more unzipping\n",
        "# !unzip -q train_labels.csv.zip\n",
        "# !unzip -q test.zip -d test \n",
        "# !unzip -q sample_submission.csv.zip\n",
        "\n",
        "# permissions\n",
        "# !chmod 644 train_labels.csv\n",
        "# !chmod 644 sample_submission.csv"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "chmod: cannot access 'sample_submission.csv': No such file or directory\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iOUyKXsLEp12",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "TRN_PATH = Path(path/'train')\n",
        "TEST_PATH = Path(path/'test')\n",
        "LABELS = Path(path/'train_labels.csv')\n",
        "WSI_LABELS = Path(path/'patch_id_wsi.csv')\n",
        "USE_GPU = torch.cuda.is_available()\n",
        "\n",
        "fixedSeed = None\n",
        "def fixSeed(seed):\n",
        "  random.seed(seed)\n",
        "  np.random.seed(seed)\n",
        "  torch.manual_seed(seed)\n",
        "  if USE_GPU:\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "\n",
        "if fixedSeed is None:\n",
        "  fixedSeed = 42  \n",
        "fixSeed(fixedSeed)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PVCj8NZWc_pw",
        "colab_type": "text"
      },
      "source": [
        "### Train/Val Split\n",
        "\n",
        "- Here we split based on the file id of the Whole Slide Image (WSI), as to not overfit to the way they are named.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "HIv08clbx4d9",
        "colab_type": "code",
        "outputId": "c24a6f75-3450-4655-f0c7-e52b9c17f813",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "# Note the label imbalance\n",
        "trn_labels = pd.read_csv(LABELS)\n",
        "trn_labels['label'].value_counts() "
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    130908\n",
              "1     89117\n",
              "Name: label, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EzuGZCWOEp1-",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# adapted from https://www.kaggle.com/c/histopathologic-cancer-detection/discussion/84132\n",
        "def return_tumor_or_not(dic, one_id):\n",
        "  return dic[one_id]\n",
        "\n",
        "def create_dict():\n",
        "  df = pd.read_csv(LABELS)\n",
        "  result_dict = {}\n",
        "  for index in range(df.shape[0]):\n",
        "    one_id = df.iloc[index,0]\n",
        "    tumor_or_not = df.iloc[index,1]\n",
        "    result_dict[one_id] = int(tumor_or_not)\n",
        "  return result_dict\n",
        "\n",
        "def find_missing(train_ids, cv_ids):\n",
        "  all_ids = set(pd.read_csv(LABELS)['id'].values)\n",
        "  wsi_ids = set(train_ids + cv_ids)\n",
        "  missing_ids = list(all_ids-wsi_ids)\n",
        "  return missing_ids\n",
        "\n",
        "\n",
        "def generate_split():\n",
        "  ids = pd.read_csv(WSI_LABELS)\n",
        "  wsi_dict = {}\n",
        "  for i in range(ids.shape[0]):\n",
        "    wsi = ids.iloc[i,1]\n",
        "    train_id = ids.iloc[i,0]\n",
        "    wsi_array = wsi.split('_')\n",
        "    number = int(wsi_array[3])\n",
        "    if wsi_dict.get(number) is None:\n",
        "      wsi_dict[number] = [train_id]\n",
        "    else:\n",
        "      wsi_dict[number].append(train_id)\n",
        "\n",
        "  wsi_keys = list(wsi_dict.keys())\n",
        "  np.random.shuffle(wsi_keys)\n",
        "  amount_of_keys = len(wsi_keys)\n",
        "\n",
        "  keys_for_train = wsi_keys[0:int(amount_of_keys*0.9)]\n",
        "  keys_for_cv = wsi_keys[int(amount_of_keys*0.9):]\n",
        "  train_ids = []\n",
        "  cv_ids = []\n",
        "\n",
        "  for key in keys_for_train:\n",
        "    train_ids += wsi_dict[key]\n",
        "\n",
        "  for key in keys_for_cv:\n",
        "    cv_ids += wsi_dict[key]\n",
        "\n",
        "  dic = create_dict()\n",
        "\n",
        "  missing_ids = find_missing(train_ids, cv_ids)\n",
        "  missing_ids_total = len(missing_ids)\n",
        "  np.random.shuffle(missing_ids)\n",
        "\n",
        "  train_missing_ids = missing_ids[0:int(missing_ids_total*0.9)]\n",
        "  cv_missing_ids = missing_ids[int(missing_ids_total*0.9):]\n",
        "\n",
        "  train_ids += train_missing_ids\n",
        "  cv_ids += cv_missing_ids\n",
        "\n",
        "  train_labels = []\n",
        "  cv_labels = []\n",
        "\n",
        "  train_tumor = 0\n",
        "  for one_id in train_ids:\n",
        "    temp = return_tumor_or_not(dic, one_id)\n",
        "    train_tumor += temp\n",
        "    train_labels.append(temp)\n",
        "\n",
        "  cv_tumor = 0\n",
        "  for one_id in cv_ids:\n",
        "    temp = return_tumor_or_not(dic, one_id)\n",
        "    cv_tumor += temp\n",
        "    cv_labels.append(temp)\n",
        "  total = len(train_ids) + len(cv_ids)\n",
        "\n",
        "  print(\"Amount of train labels: {}, {}/{}\".format(len(train_ids), train_tumor, len(train_ids)-train_tumor))\n",
        "  print(\"Amount of cv labels: {}, {}/{}\".format(len(cv_ids), cv_tumor, len(cv_ids) - cv_tumor))\n",
        "  print(\"Percentage of cv labels: {}\".format(len(cv_ids)/total))\n",
        "\n",
        "  return train_ids, cv_ids, train_labels, cv_labels\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gSvBx83ZEp2A",
        "colab_type": "text"
      },
      "source": [
        "### DataLoader & Transforms "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n5rbvwC7Ep2A",
        "colab_type": "text"
      },
      "source": [
        "H&E produces blue and different shades of pink colors:\n",
        "    - Hematoxylin is dark blue and binds to negatively charged compounds i.e. nucleic acids\n",
        "    - Eosin is pink and binds to positively charged compounds i.e. amino-acid side chains in most proteins, cytoplasm, extracellular features"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GmWbTGZAEp2B",
        "colab_type": "text"
      },
      "source": [
        " We experimented with stain normalization but this did not improve performance. Normalizing over the image values proved to be more effective than stain normalization. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "iTHe0qylf_Cx",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class BaseDataset(Dataset):\n",
        "  def __init__(self,\n",
        "                x_ds: Dataset,\n",
        "                y_ds: Dataset,\n",
        "                x_tfms: Optional = None):\n",
        "    self.x_ds = x_ds\n",
        "    self.y_ds = y_ds\n",
        "    self.x_tfms = x_tfms\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return self.x_ds.__len__()\n",
        "\n",
        "  def __getitem__(self, index: int) -> Tuple:\n",
        "    x = self.x_ds[index]\n",
        "    y = self.y_ds[index]\n",
        "    if self.x_tfms is not None:\n",
        "      x = self.x_tfms(x)\n",
        "      return x, y\n",
        "      \n",
        "class WSILabelDataset(Dataset):\n",
        "  def __init__(self, labels: List):\n",
        "    self.labels = labels\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.labels)\n",
        "\n",
        "  def __getitem__(self, index: int) -> int:\n",
        "    return self.labels[index]\n",
        "\n",
        "class WSIDataset(Dataset):\n",
        "  def __init__(self, img_paths: List):\n",
        "    self.img_paths = img_paths\n",
        "\n",
        "  def __len__(self) -> int:\n",
        "    return len(self.img_paths)\n",
        "\n",
        "  def __getitem__(self, index: int) -> Image.Image:\n",
        "    img = Image.open(self.img_paths[index])\n",
        "    return img"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "QqcgCGQZEp2U",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "bs = 256\n",
        "n_workers = 0\n",
        "kaggle_stats = [[0.485, 0.456, 0.406],\n",
        "        [0.229, 0.224, 0.225]]\n",
        "size = 96 # initial size\n",
        "lr = 4e-2 # determined via fast.ai lr_find()\n",
        "# more intensive transforms seemed to help validation score\n",
        "tfms = transforms.Compose([\n",
        "    transforms.Resize((size, size)),\n",
        "    transforms.RandomChoice([\n",
        "      transforms.ColorJitter(brightness=0.5),\n",
        "      transforms.ColorJitter(contrast=0.5), \n",
        "      transforms.ColorJitter(saturation=0.5),\n",
        "      transforms.ColorJitter(hue=0.5),\n",
        "      transforms.ColorJitter(brightness=0.1, contrast=0.1, saturation=0.1, hue=0.1), \n",
        "      transforms.ColorJitter(brightness=0.3, contrast=0.3, saturation=0.3, hue=0.3), \n",
        "      transforms.ColorJitter(brightness=0.5, contrast=0.5, saturation=0.5, hue=0.5), \n",
        "    ]),\n",
        "    transforms.RandomChoice([\n",
        "      transforms.RandomRotation((0,0)),\n",
        "      transforms.RandomHorizontalFlip(p=1),\n",
        "      transforms.RandomVerticalFlip(p=1),\n",
        "      transforms.RandomRotation((90,90)),\n",
        "      transforms.RandomRotation((180,180)),\n",
        "      transforms.RandomRotation((270,270)),\n",
        "      transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(p=1),\n",
        "          transforms.RandomRotation((90,90)),\n",
        "      ]),\n",
        "      transforms.Compose([\n",
        "          transforms.RandomHorizontalFlip(p=1),\n",
        "          transforms.RandomRotation((270,270)),\n",
        "      ]) \n",
        "    ]),\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(\n",
        "      mean=kaggle_stats[0],\n",
        "      std=kaggle_stats[1]\n",
        "    )\n",
        "])\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1ITZc5RUngIp",
        "colab_type": "code",
        "outputId": "1560e140-4790-4e4b-e283-fe129d1dfc3b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        }
      },
      "source": [
        "train_ids, val_ids, train_labels, val_labels = generate_split()\n",
        "fn_paths = [TRN_PATH/(name+'.tif') for name in train_ids]\n",
        "valid_paths = [id+'.tif' for id in val_ids]\n",
        "\n",
        "trn_img_ds = WSIDataset(fn_paths)\n",
        "val_img_ds = WSIDataset(valid_paths)\n",
        "trn_lbl_ds = WSILabelDataset(train_labels)\n",
        "val_lbl_ds = WSILabelDataset(val_labels)\n",
        "\n",
        "trn_ds = BaseDataset(trn_img_ds,trn_lbl_ds, x_tfms=tfms)\n",
        "val_ds = BaseDataset(val_img_ds,trn_lbl_ds, x_tfms=tfms)\n",
        "trn_dl = DataLoader(trn_ds,batch_size=bs,shuffle=True,num_workers=n_workers)\n",
        "val_dl = DataLoader(val_ds,batch_size=bs,shuffle=False,num_workers=n_workers)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Amount of train labels: 197458, 81040/116418\n",
            "Amount of cv labels: 22567, 8077/14490\n",
            "Percentage of cv labels: 0.10256561754346097\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J2EPnSkPS7pn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_t(tensor):\n",
        "  if not torch.is_tensor(tensor):\n",
        "    tensor = torch.FloatTensor(tensor)\n",
        "  else:\n",
        "    tensor = tensor.type(torch.FloatTensor)\n",
        "  if USE_GPU:\n",
        "    tensor = to_gpu(tensor)\n",
        "  return tensor\n",
        "\n",
        "\n",
        "def to_numpy(tensor: Union[Tensor, Image.Image, np.array]) -> np.ndarray:\n",
        "  if type(tensor) == np.array or type(tensor) == np.ndarray:\n",
        "    return np.array(tensor)\n",
        "  elif type(tensor) == Image.Image:\n",
        "    return np.array(tensor)\n",
        "  elif type(tensor) == Tensor:\n",
        "    return tensor.cpu().detach().numpy()\n",
        "  else:\n",
        "    raise ValueError(msg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jKfoMacreTxq",
        "colab_type": "text"
      },
      "source": [
        "## Model & Training Loop\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RolH5VABeXtB",
        "colab_type": "text"
      },
      "source": [
        "Heavily influenced by this series of posts on training optimization:\n",
        "https://myrtle.ai/how-to-train-your-resnet-8-bag-of-tricks/"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HYQ_-0tslKWr",
        "colab_type": "text"
      },
      "source": [
        "Here we use base PyTorch but in practice, the One Cycle Scheduler available from fast.ai and progressive resizing (96, 128, 192) was added to the mix."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3O5A8rszEp2B",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def to_gpu(tensor):\n",
        "  return tensor.cuda() if USE_GPU else tensor\n",
        "def resnet9(pretrained=True,output_dim: int = 1, **kwargs):\n",
        "  \"\"\"Constructs a ResNet-9 model.\n",
        "  Args:\n",
        "      pretrained (bool): If True, returns a model pre-trained on ImageNet\n",
        "  \"\"\"\n",
        "  model = ResNet(BasicBlock, [1,1,1,1], **kwargs)\n",
        "  in_features = model.fc.in_features\n",
        "  model.avgpool = nn.AdaptiveAvgPool2d(1)\n",
        "  model.fc = nn.Linear(in_features, output_dim)\n",
        "  model = to_gpu(model)\n",
        "  return model\n",
        "m = resnet9(output_dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "OPmCDgwyRuub",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def one_epoch(\n",
        "    model,\n",
        "    trn_dl,\n",
        "    val_dl,\n",
        "    loss_func,\n",
        "    opt_func,\n",
        "    trn_loss_writer,\n",
        "    val_loss_writer,\n",
        "    do_step_trig,\n",
        "    trn_loss_trig,\n",
        "    val_loss_trig):\n",
        "  model.train()\n",
        "  y_targ_trn, y_pred_trn = [], []\n",
        "  for i, (x,y) in enumerate(trn_dl):\n",
        "    x = Variable(to_t(x), requires_grad=True)\n",
        "    y = Variable(to_t(y), requires_grad=True)\n",
        "    out = model(x)\n",
        "    y_targ_trn.append(to_numpy(y))\n",
        "    y_pred_train.append(to_numpy(out))\n",
        "    losses = loss(out, y)\n",
        "    losses.backward()\n",
        "    if do_step_trig(i):\n",
        "      opt.step()\n",
        "      opt.zero_grad()\n",
        "    if trn_loss_trig(i):\n",
        "      auc_metric(y_targ_trn, y_pred_trn, i)\n",
        "      y_targ_trn, y_pred_trn = [], []\n",
        "    if val_loss_trig(i):\n",
        "      y_targ, y_pred = predict(model, val_dl)\n",
        "      auc_metric(y_targ, y_pred, i)\n",
        "  return model\n",
        "\n",
        "def predict(model, dl):\n",
        "  model.eval()\n",
        "  y_targ, y_pred = [], []\n",
        "  with torch.no_grad():\n",
        "    for x, y in dataloader:\n",
        "      x = Variable(to_t(x))\n",
        "      y = Variable(to_t(y))\n",
        "      out = model(x)\n",
        "      y_targ.append(to_numpy(y))\n",
        "      y_pred.append(to_numpy(out))\n",
        "  return y_targ, y_pred\n",
        "\n",
        "def iter_trig(iter_num, step_size):\n",
        "  if step_size == 1:\n",
        "    return True\n",
        "  elif iter_num > 0 and iter_num % step_size == 0:\n",
        "    return True\n",
        "  else:\n",
        "    return False\n",
        "\n",
        "# Competition uses AUC as ranking metric\n",
        "def auc_metric(y_targ, y_pred, iter_num):\n",
        "  try:\n",
        "    auc = roc_auc_score(np.vstack(y_targ), np.vstack(y_pred)) \n",
        "  except:\n",
        "    auc = -1\n",
        "  logger.info(f'iter #: {iter_num}, auc: {auc}')\n",
        "\n",
        "def init_trigs(step_size=1, val=10, trn=10):\n",
        "  do_step_trig = partial(iter_trig, step_size=step_size)\n",
        "  trn_loss_trig = partial(iter_trig, step_size=trn)\n",
        "  val_loss_trig = partial(iter_trig, step_size=val)\n",
        "  return do_step_trig, trn_loss_trig, val_loss_trig"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CA74lye5RPt7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "m = resnet9(output_dim=1)\n",
        "optimizer = Adam(m.parameters(),lr=lr)\n",
        "loss = nn.BCEWithLogitsLoss()\n",
        "loss_writer_trn = auc_metric\n",
        "loss_writer_val = auc_metric\n",
        "do_step_trig, trn_loss_trig, val_loss_trig = init_trigs(1,10,10)\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6CKqeIKjlwE8",
        "colab_type": "text"
      },
      "source": [
        "## Training"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "AkYxJyl2nNID",
        "colab_type": "text"
      },
      "source": [
        "Our single best model was progressively resized from 96 -> 128 -> 192.\n",
        "On each resizing, lr was divided by a factor of 10.\n",
        "If the validation loss did not decrease after ~5 cycles, lr was divided by 2. Then if loss still did not improve, previous best model was loaded."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLf-GcqpZa4w",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "learn = one_epoch(m,\n",
        "                  trn_dl,\n",
        "                  val_dl,\n",
        "                  loss,\n",
        "                  optimizer,\n",
        "                  loss_writer_trn,\n",
        "                  loss_writer_val,\n",
        "                  do_step_trig,\n",
        "                  trn_loss_trig,\n",
        "                  val_loss_trig)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ALsoj6rcmeQM",
        "colab_type": "text"
      },
      "source": [
        "## Classification Interpretation"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Lu828ieBhNIu",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "y_targ, y_pred = predict(m, val_dl)\n",
        "preds = pd.DataFrame(list(zip(val_lbls.reshape(-1),np.vstack(y_pred).reshape(-1),valid_paths)),columns=['Label','Pred','fn'])\n",
        "plot_limit = 20\n",
        "def show_preds(fns, w=2, h=2, n_cols=5):\n",
        "  n_rows = len(fns) / n_cols + 1\n",
        "  imgs = [Image.open(f) for f in fns]\n",
        "  plt.figure(figsize = (n_cols * w, n_rows * h))\n",
        "  plt.tight_layout()\n",
        "  for chart, img in enumerate(imgs, 1):\n",
        "    ax = plt.subplot(n_rows, n_cols, chart)\n",
        "    ax.imshow(np.array(img))\n",
        "    ax.axis('off')\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qQ_qaDLOjSgr",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# False negative imgs\n",
        "false_neg = preds[preds['Label']==1].sort_values('Pred', ascending=True)['fn'].values[:plot_limit]\n",
        "implot(false_neg)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IGmiD4jZjtrA",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# False positive imgs\n",
        "false_pos = preds[preds['Label']==0].sort_values('Pred', ascending=False)['fn'].values[:plot_limit]\n",
        "implot(false_pos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5xgxlxXgj3Yv",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# True positive imgs\n",
        "true_pos = preds[preds['Label']==1].sort_values('Pred', ascending=False)['fn'].values[:plot_limit]\n",
        "implot(true_pos)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oVXrOcjZkGyf",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# True negative imgs\n",
        "true_neg = preds[preds['Label']==0].sort_values('Pred', ascending=True)['fn'].values[:plot_limit]\n",
        "implot(true_neg)"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}